{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2057400,
          "sourceType": "datasetVersion",
          "datasetId": 1232901
        }
      ],
      "dockerImageVersionId": 30120,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'eyes-open-or-closed:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1232901%2F2057400%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240226%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240226T034456Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da41d6d8e266c4493ef11e13d84104eb50c48c582cfb6af89c571d4d3f9e439246fcbbe3bff253cb33da0ad2cde73f1bdd2091f8fad119094e37e5d875fc6cd7a7c588385b8e3c3d3e7e4ca031a884b2297944da803c8b4447aed1062a6321106a8b8a45054e9e39e2a20ff8217d68e27c3f238420e2bb27b31960b1886f672c66d1436d37ec24bb7e77220b794737324a419439a576e439111c36ee5816873f3e73d8ae013e0e943ad85623079dffc3245f08ff3d29ec89ea70135393ff638a5de31b268962e0c499f6b887861286585f0c763df92faf36c85b82a8cad40edce45e6785161edaf3ef89658284deb7b3ceacbe4896be6c1895f528adc6a9c9e9a'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCl17PARj2We",
        "outputId": "6b7f6fe6-e6d6-4dfe-eb6a-f164d32ad83d"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading eyes-open-or-closed, 23747803 bytes compressed\n",
            "[==================================================] 23747803 bytes downloaded\n",
            "Downloaded and uncompressed: eyes-open-or-closed\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "train_dir ='../input/eyes-open-or-closed/dataset/train'\n",
        "test_dir  ='../input/eyes-open-or-closed/dataset/test'"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-02-26T03:29:50.533319Z",
          "iopub.execute_input": "2024-02-26T03:29:50.533769Z",
          "iopub.status.idle": "2024-02-26T03:29:58.458266Z",
          "shell.execute_reply.started": "2024-02-26T03:29:50.53366Z",
          "shell.execute_reply": "2024-02-26T03:29:58.457356Z"
        },
        "id": "LokDfVn2j2Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width, height = 86, 86\n",
        "training=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0,\n",
        "                                                          rotation_range=7,\n",
        "                                                          horizontal_flip=True,\n",
        "                                                          validation_split=0.05\n",
        "                                                         ).flow_from_directory(train_dir,\n",
        "                                                                               class_mode = 'categorical',\n",
        "                                                                               batch_size = 8,\n",
        "                                                           target_size=(width,height),\n",
        "                                                                              subset=\"training\")\n",
        "testing=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0,\n",
        "                                                         ).flow_from_directory(test_dir,\n",
        "                                                                               class_mode = 'categorical',\n",
        "                                                                               batch_size = 8,\n",
        "                                                                               shuffle = False,\n",
        "                                                           target_size=(width,height))\n",
        "validing=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0,\n",
        "                                                          rotation_range=7,\n",
        "                                                          horizontal_flip=True,\n",
        "                                                         validation_split=0.05\n",
        "                                                        ).flow_from_directory(train_dir,\n",
        "                                                                              batch_size = 8,\n",
        "                                                                              class_mode = 'categorical',\n",
        "                                                           target_size=(width,height),subset='validation',shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T03:29:58.462907Z",
          "iopub.execute_input": "2024-02-26T03:29:58.464984Z",
          "iopub.status.idle": "2024-02-26T03:30:00.448891Z",
          "shell.execute_reply.started": "2024-02-26T03:29:58.464927Z",
          "shell.execute_reply": "2024-02-26T03:30:00.447953Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FjSWbk6j2Wf",
        "outputId": "f3a44d01-21f3-4fb9-da01-fe57e576d6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3230 images belonging to 2 classes.\n",
            "Found 600 images belonging to 2 classes.\n",
            "Found 170 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential ,Model\n",
        "from keras.layers import Dense ,Flatten ,Conv2D ,MaxPooling2D ,Dropout ,BatchNormalization  ,Activation ,GlobalMaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping ,ReduceLROnPlateau"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T03:30:00.452985Z",
          "iopub.execute_input": "2024-02-26T03:30:00.453649Z",
          "iopub.status.idle": "2024-02-26T03:30:00.531782Z",
          "shell.execute_reply.started": "2024-02-26T03:30:00.453604Z",
          "shell.execute_reply": "2024-02-26T03:30:00.530776Z"
        },
        "trusted": true,
        "id": "FwCfzneSj2Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.99)\n",
        "EarlyStop = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "Reduce_LR = ReduceLROnPlateau(monitor='val_accuracy', verbose=2, factor=0.5, min_lr=0.00001)\n",
        "callbacks = [EarlyStop, Reduce_LR]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T03:30:00.536391Z",
          "iopub.execute_input": "2024-02-26T03:30:00.538675Z",
          "iopub.status.idle": "2024-02-26T03:30:00.553086Z",
          "shell.execute_reply.started": "2024-02-26T03:30:00.53862Z",
          "shell.execute_reply": "2024-02-26T03:30:00.551836Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLierW0Pj2Wf",
        "outputId": "8c048ebd-91ec-486e-d814-4b27cc33085f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "num_detectors=32\n",
        "\n",
        "network = Sequential()\n",
        "\n",
        "network.add(Conv2D(num_detectors, (3,3), activation='relu', padding = 'same', input_shape = (width, height, 3)))\n",
        "network.add(BatchNormalization())\n",
        "network.add(Conv2D(num_detectors, (3,3), activation='relu', padding = 'same'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(MaxPooling2D(pool_size=(2,2)))\n",
        "network.add(Dropout(0.2))\n",
        "\n",
        "network.add(Conv2D(2*num_detectors, (3,3), activation='relu', padding = 'same'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(Conv2D(2*num_detectors, (3,3), activation='relu', padding = 'same'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(MaxPooling2D(pool_size=(2,2)))\n",
        "network.add(Dropout(0.2))\n",
        "\n",
        "network.add(Conv2D(2*2*num_detectors, (3,3), activation='relu', padding = 'same'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(Conv2D(2*2*num_detectors, (3,3), activation='relu', padding = 'same'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(MaxPooling2D(pool_size=(2,2)))\n",
        "network.add(Dropout(0.2))\n",
        "\n",
        "network.add(Conv2D(2*2*2*num_detectors, (3,3), activation='relu', padding = 'same'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(Conv2D(2*2*2*num_detectors, (3,3), activation='relu', padding = 'same'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(MaxPooling2D(pool_size=(2,2)))\n",
        "network.add(Dropout(0.2))\n",
        "\n",
        "network.add(Flatten())\n",
        "\n",
        "network.add(Dense(2 * num_detectors, activation='relu'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(Dropout(0.2))\n",
        "\n",
        "network.add(Dense(2 * num_detectors, activation='relu'))\n",
        "network.add(BatchNormalization())\n",
        "network.add(Dropout(0.2))\n",
        "\n",
        "network.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T03:30:00.558006Z",
          "iopub.execute_input": "2024-02-26T03:30:00.55989Z",
          "iopub.status.idle": "2024-02-26T03:30:01.006121Z",
          "shell.execute_reply.started": "2024-02-26T03:30:00.559839Z",
          "shell.execute_reply": "2024-02-26T03:30:01.005199Z"
        },
        "trusted": true,
        "id": "Zf6sFSv6j2Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T03:30:01.0104Z",
          "iopub.execute_input": "2024-02-26T03:30:01.012521Z",
          "iopub.status.idle": "2024-02-26T03:30:01.033662Z",
          "shell.execute_reply.started": "2024-02-26T03:30:01.01247Z",
          "shell.execute_reply": "2024-02-26T03:30:01.032756Z"
        },
        "trusted": true,
        "id": "2UlHF13Cj2Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T03:30:01.038141Z",
          "iopub.execute_input": "2024-02-26T03:30:01.040616Z",
          "iopub.status.idle": "2024-02-26T03:30:01.06586Z",
          "shell.execute_reply.started": "2024-02-26T03:30:01.040556Z",
          "shell.execute_reply": "2024-02-26T03:30:01.065003Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKbG3bzCj2Wg",
        "outputId": "549cd1e6-d232-4df2-f04e-b4dd4b485d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 86, 86, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 86, 86, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 86, 86, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 86, 86, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 43, 43, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 43, 43, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 43, 43, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 43, 43, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 43, 43, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 43, 43, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 21, 21, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 21, 21, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 21, 21, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 21, 21, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 21, 21, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 21, 21, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 10, 10, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 10, 10, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 10, 10, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 10, 10, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                409664    \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1590562 (6.07 MB)\n",
            "Trainable params: 1588386 (6.06 MB)\n",
            "Non-trainable params: 2176 (8.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = network.fit(training, validation_data=validing, epochs=20, callbacks=callbacks, verbose=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-26T03:30:01.070547Z",
          "iopub.execute_input": "2024-02-26T03:30:01.072662Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwhksBPwj2Wg",
        "outputId": "48363b1b-b05b-46ce-d232-c843fe8c1413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "404/404 - 218s - loss: 0.3181 - accuracy: 0.8808 - val_loss: 0.6692 - val_accuracy: 0.6706 - lr: 0.0010 - 218s/epoch - 539ms/step\n",
            "Epoch 2/20\n",
            "404/404 - 216s - loss: 0.1969 - accuracy: 0.9285 - val_loss: 0.3561 - val_accuracy: 0.8353 - lr: 0.0010 - 216s/epoch - 535ms/step\n",
            "Epoch 3/20\n",
            "404/404 - 213s - loss: 0.1089 - accuracy: 0.9628 - val_loss: 0.5716 - val_accuracy: 0.8059 - lr: 0.0010 - 213s/epoch - 528ms/step\n",
            "Epoch 4/20\n",
            "404/404 - 210s - loss: 0.0882 - accuracy: 0.9718 - val_loss: 0.0202 - val_accuracy: 0.9941 - lr: 0.0010 - 210s/epoch - 519ms/step\n",
            "Epoch 5/20\n",
            "404/404 - 214s - loss: 0.0570 - accuracy: 0.9820 - val_loss: 0.1243 - val_accuracy: 0.9588 - lr: 0.0010 - 214s/epoch - 530ms/step\n",
            "Epoch 6/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val,los=network.evaluate(testing)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9enREXmcj2Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics = history.history\n",
        "plt.plot(history.epoch, metrics['loss'])\n",
        "plt.legend(['loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "4_Pb1000j2Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network.save('eyes.h5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "VL1ScuGTj2Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xNyp04pFj2Wh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}